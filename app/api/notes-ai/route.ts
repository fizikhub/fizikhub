import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextRequest, NextResponse } from "next/server";

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GENERATIVE_AI_API_KEY!);

const SYSTEM_PROMPT = `Sen FizikHub'Ä±n yapay zeka not asistanÄ±sÄ±n. KimliÄŸin: **Gemini 2.5 Flash Native Audio Dialog**. 
TÃ¼rkÃ§e konuÅŸuyorsun ve kullanÄ±cÄ±lara not alma, dÃ¼zenleme ve Ã¶ÄŸrenme konularÄ±nda yardÄ±mcÄ± oluyorsun.

TEMEL GÃ–REVLERÄ°N:
1. Sesli veya yazÄ±lÄ± komutlarÄ± anla ve nota uygula (not al, baÅŸlÄ±k deÄŸiÅŸtir, listele).
2. Mevcut notu analiz et: Ã–zet Ã§Ä±kar, kategori Ã¶ner, etiket Ã¼ret.
3. Fizik, Matematik ve Bilim konularÄ±nda uzman desteÄŸi ver.
4. Profesyonel tonlama ve dÃ¼zenleme yap.

AKSIYON KURALLARI:
EÄŸer kullanÄ±cÄ± nota bir ÅŸey eklemeni/deÄŸiÅŸtirmeni isterse, cevabÄ±nÄ±n sonuna ÅŸu etiketleri ekle:
- Metin eklemek/deÄŸiÅŸtirmek iÃ§in: [ACTION:INSERT_TEXT]yeni iÃ§erik[/ACTION]
- BaÅŸlÄ±k deÄŸiÅŸtirmek iÃ§in: [ACTION:INSERT_TITLE]yeni baÅŸlÄ±k[/ACTION]

Ã–NEMLÄ°:
- KÄ±sa, Ã¶z ve etkileyici cevaplar ver.
- Sesli diyalogda olduÄŸun iÃ§in doÄŸal bir konuÅŸma dili kullan.
- Emoji kullanÄ±mÄ± serbesttir. ðŸš€

MEVCUT NOT BÄ°LGÄ°SÄ°:
BaÅŸlÄ±k: {noteTitle}
Ä°Ã§erik: {noteContent}`;

// Define a list of models to try in order of preference
const PREFERRED_MODELS = [
    "gemini-2.5-flash",
    "gemini-2.0-flash",
    "gemini-1.5-flash-8b",
    "gemini-1.5-pro",
    "gemini-1.5-flash"
];

async function tryGenerateContent(requestId: string, modelName: string, parts: any[]) {
    console.log(`[AI-API][${requestId}] Attempting with model: ${modelName}`);
    try {
        const model = genAI.getGenerativeModel({
            model: modelName,
            generationConfig: {
                temperature: 0.8,
                maxOutputTokens: 2048,
                topP: 0.95,
            },
        });

        // For audio, we use simpler approach if the specific model supports it
        const result = await model.generateContent(parts);
        const response = await result.response;
        return response.text();
    } catch (err: any) {
        console.error(`[AI-API][${requestId}] Model ${modelName} failed:`, err.message);
        throw err;
    }
}

export async function POST(request: NextRequest) {
    const requestId = Math.random().toString(36).substring(7);
    console.log(`[AI-API][${requestId}] Request received`);

    try {
        const body = await request.json();
        const { type, message, audio, noteTitle, noteContent, history } = body;

        console.log(`[AI-API][${requestId}] Request Type: ${type}`);

        let userMessage = message;
        let transcription = "";
        let audioData: any = null;

        // If audio is provided, prepare it for the prompt
        if (type === "audio" && audio) {
            console.log(`[AI-API][${requestId}] Audio data received (length: ${audio.length})`);
            audioData = {
                inlineData: {
                    mimeType: "audio/webm",
                    data: audio,
                },
            };
        }

        const systemContext = SYSTEM_PROMPT
            .replace("{noteTitle}", noteTitle || "BaÅŸlÄ±ksÄ±z")
            .replace("{noteContent}", noteContent || "Ä°Ã§erik boÅŸ");

        // Build the prompt parts
        const promptParts: any[] = [];
        promptParts.push({ text: systemContext });

        // Add history
        (history || []).forEach((msg: { role: string; content: string }) => {
            promptParts.push({ text: `${msg.role === "user" ? "KullanÄ±cÄ±" : "Asistan"}: ${msg.content}` });
        });

        // Add current input
        if (audioData) {
            promptParts.push(audioData);
            promptParts.push({ text: "KullanÄ±cÄ±nÄ±n bu ses kaydÄ±nÄ± dinle ve TÃ¼rkÃ§e olarak yanÄ±t ver. EÄŸer bir komutsa (not al vs.) eyleme dÃ¶k." });
        } else {
            promptParts.push({ text: `KullanÄ±cÄ±: ${userMessage || "Merhaba"}` });
        }

        // Try models in order
        let responseText = "";
        let successModel = "";
        let lastError = null;

        for (const modelName of PREFERRED_MODELS) {
            try {
                responseText = await tryGenerateContent(requestId, modelName, promptParts);
                successModel = modelName;
                break;
            } catch (err) {
                lastError = err;
                continue;
            }
        }

        if (!successModel) {
            throw lastError || new Error("HiÃ§bir model yanÄ±t vermedi");
        }

        console.log(`[AI-API][${requestId}] Success with ${successModel}`);

        // Extract transcription if it was an audio request (Gemini returns the text as part of response usually)
        if (type === "audio") {
            // Simplified: we'll treat the response as both the transcription and the dialogue
            // In a more complex setup, we could ask for both in one go.
            transcription = "[Ses KaydÄ± Ä°ÅŸlendi]";
        }

        // Action Parsing
        let action = null;
        let actionData = null;

        const textMatch = responseText.match(/\[ACTION:INSERT_TEXT\]([\s\S]*?)\[\/ACTION\]/);
        const titleMatch = responseText.match(/\[ACTION:INSERT_TITLE\]([\s\S]*?)\[\/ACTION\]/);

        if (textMatch) {
            action = "insert_text";
            actionData = { text: textMatch[1].trim() };
            responseText = responseText.replace(textMatch[0], "").trim();
            console.log(`[AI-API][${requestId}] Action found: INSERT_TEXT`);
        }

        if (titleMatch) {
            action = "insert_title";
            actionData = { title: titleMatch[1].trim() };
            responseText = responseText.replace(titleMatch[0], "").trim();
            console.log(`[AI-API][${requestId}] Action found: INSERT_TITLE`);
        }

        return NextResponse.json({
            success: true,
            response: responseText,
            transcription: transcription || undefined,
            action,
            ...(actionData || {}),
            debug: { model: successModel }
        });
    } catch (error: any) {
        console.error(`[AI-API][${requestId}] Fatal Error:`, error);
        return NextResponse.json(
            { success: false, error: error.message || "Bir hata oluÅŸtu", details: error.toString() },
            { status: 500 }
        );
    }
}
